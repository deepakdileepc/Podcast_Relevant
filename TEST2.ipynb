{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAYneMvbeb7r",
    "outputId": "6bf9148d-e2f6-44b8-d852-b08898a61e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.52.2\n",
      "    Uninstalling openai-1.52.2:\n",
      "      Successfully uninstalled openai-1.52.2\n",
      "Successfully installed openai-0.28.0 python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28 python-dotenv\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuhDcFgSeo6U",
    "outputId": "7dc8fcd2-8559-4ea1-e76c-5f3e770a363a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clues Response:  mysteries, transparently obvious, slowly paced, thriller\n",
      "Reasoning Response: \n",
      "The input mentions that the subject matter at hand is \"mysteries,\" and that these mysteries are \"transparently obvious.\" This suggests that the content of the input may be easily understood or solved. Additionally, the input states that the subject matter is \"too slowly paced to be a thriller.\" This implies that the content is not fast-paced or action-packed, which are typical characteristics of a thriller genre. Therefore, through the clues provided, it can be deduced that the input is likely not a thriller, but rather a genre that involves mysteries that are easy to understand. \n",
      "Sentiment Determination Response:  Negative\n",
      "Final Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "def classify_text_improved(input_text, model=\"gpt-3.5-turbo-instruct\"):\n",
    "\n",
    "    # Step 1: Identify Clues\n",
    "    clues_prompt = (\n",
    "        f\"This is an overall sentiment classifier.\\n\"\n",
    "        f\"First, list CLUES (i.e., keywords, phrases, contextual information, semantic relations, \"\n",
    "        f\"semantic meaning, tones, references) that support the sentiment determination of the input.\\n\"\n",
    "        f\"Input: {input_text}\\n\"\n",
    "        f\"Clues:\"\n",
    "    )\n",
    "\n",
    "    response_clues = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=clues_prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    clues = response_clues.choices[0].text.strip()\n",
    "    print(\"Clues Response:\", response_clues.choices[0].text)  # Print Clues Response\n",
    "\n",
    "    # Step 2: Diagnostic Reasoning\n",
    "    reasoning_prompt = (\n",
    "        f\"Based on the input and clues, deduce the diagnostic reasoning process from premises \"\n",
    "        f\"(i.e., clues and input) that supports the sentiment determination of the input.\\n\"\n",
    "        f\"Input: {input_text}\\n\"\n",
    "        f\"Clues: {clues}\\n\"\n",
    "        f\"Reasoning:\"\n",
    "    )\n",
    "\n",
    "    response_reasoning = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=reasoning_prompt,\n",
    "        max_tokens=130,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    reasoning = response_reasoning.choices[0].text.strip()\n",
    "    print(\"Reasoning Response:\", response_reasoning.choices[0].text)  # Print Reasoning Response\n",
    "\n",
    "    # Step 3: Final Sentiment Determination\n",
    "    sentiment_prompt = (\n",
    "        f\"Considering the clues and reasoning, determine the overall SENTIMENT of the input as Positive, \"\n",
    "        f\"or Negative.\\n\"\n",
    "        f\"Input: {input_text}\\n\"\n",
    "        f\"Clues: {clues}\\n\"\n",
    "        f\"Reasoning: {reasoning}\\n\"\n",
    "        f\"Sentiment:\"\n",
    "    )\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=sentiment_prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    print(\"Sentiment Determination Response:\", response.choices[0].text)  # Print Sentiment Response\n",
    "\n",
    "    # Process the sentiment result\n",
    "    try:\n",
    "        response = response.choices[0].text\n",
    "        sentiment = response.lower().split(\"sentiment:\")[-1].strip()\n",
    "\n",
    "        if \"neg\" in sentiment:\n",
    "            sentiment = 0\n",
    "        elif \"pos\" in sentiment:\n",
    "            sentiment = 1\n",
    "        else:\n",
    "            print(response)\n",
    "            sentiment = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentiment: {e}\")\n",
    "        print(response)\n",
    "        sentiment = None\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_text = \"its mysteries are transparently obvious , and it 's too slowly paced to be a thriller\"\n",
    "result = classify_text_improved(input_text)\n",
    "\n",
    "print(\"Final Sentiment:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
